import requests
from bs4 import BeautifulSoup
import pandas as pd

class NoFluffJobsScraper:
    def __init__(self, url):
        self.url = url

    def scrape(self):
        page = requests.get(self.url)
        soup = BeautifulSoup(page.content, 'html.parser')
        results = soup.find(id='job-list')
        job_elems = results.find_all('div', class_='posting-item')

        titles = []
        companies = []
        locations = []

        for job_elem in job_elems:
            title_elem = job_elem.find('div', class_='posting-item-title')
            title = title_elem.text.strip().split(' w ')[0]
            titles.append(title)

            company_elem = job_elem.find('div', class_='posting-item-title')
            company = company_elem.text.strip().split(' w ')[1].split(',')[0]
            companies.append(company)

            location_elem = job_elem.find('div', class_='posting-item-title')
            location = location_elem.text.strip().split(' w ')[1].split(',')[1].strip()
            locations.append(location)

        data = {'Title': titles, 'Company': companies, 'Location': locations}
        df = pd.DataFrame(data)

        return df

    def save_to_csv(self, filename):
        df = self.scrape()
        df.to_csv(filename, index=False)
